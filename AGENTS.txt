FHA Data Manager â€“ Agent Guide

Schemas

Single Family (cleaned monthly snapshots)
- Property State: string
- Property City: string
- Property County: string
- Property Zip: int32
- Originating Mortgagee: string
- Originating Mortgagee Number: int32
- Sponsor Name: string
- Sponsor Number: int32
- Down Payment Source: string
- Non Profit Number: int64
- Product Type: string
- Loan Purpose: string
- Property Type: string
- Interest Rate: float64
- Mortgage Amount: int64
- Year: int16
- Month: int16
- FHA_Index: string

HECM (cleaned monthly snapshots)
- Property State: string
- Property City: string
- Property County: string
- Property Zip: int32
- Originating Mortgagee: string
- Originating Mortgagee Number: int32
- Sponsor Name: string
- Sponsor Number: int32
- Sponsor Originator: string
- NMLS: int64
- Standard/Saver: string
- Purchase/Refinance: string
- Rate Type: string
- Interest Rate: float64
- Initial Principal Limit: float64
- Maximum Claim Amount: float64
- Year: int16
- Month: int16
- Current Servicer ID: int64
- Previous Servicer ID: int64
- FHA_Index: string

Where data live
- Raw downloads: data/raw/single_family, data/raw/hecm
- Cleaned monthly parquet: data/clean/single_family, data/clean/hecm
- Hive-structured database: data/database/{single_family|hecm}/Year=YYYY/Month=M/*.parquet

Key scripts
- download_fha_data.py: Downloads snapshots and standardizes filenames (fha_sf_snapshot_YYYYMM01.*, fha_hecm_snapshot_YYYYMM01.*)
- import_fha_data.py: Cleans monthly files to parquet and saves to hive-structured database

Typical workflow
1) Download snapshots
   python download_fha_data.py

2) Clean monthly files and save to hive-structured database
   python import_fha_data.py
   # Produces monthly parquet in data/clean/{single_family|hecm} and hive-structured database in data/database/

Interacting with data (examples)
- Read Single Family from hive-structured database
   import polars as pl
   df = pl.scan_parquet('data/database/single_family')

- Read HECM from hive-structured database
   import polars as pl
   df = pl.scan_parquet('data/database/hecm')

- Query with PyArrow
   from pyarrow import dataset as ds
   tbl = ds.dataset('data/database/single_family', format='parquet')

Notes
- Cleaners enforce schema with the dictionaries in mtgdicts.py.
- Required columns for downstream tools include Year and Month.
- FHA_Index is unique within each monthly file and built from YYYYMM01_row.
